{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))\n",
    "sys.path.append(os.path.abspath(\"../../backend\"))\n",
    "sys.path.append(os.path.abspath(\"\"))\n",
    "\n",
    "\n",
    "from rdflib.plugins.stores.sparqlstore import SPARQLStore\n",
    "\n",
    "from backend.ontology import OntologyConfig, OntologyManager, Graph\n",
    "from backend.explorative.explorative_support import (\n",
    "    GuidanceManager,\n",
    ")\n",
    "from backend.explorative.llm_query import (\n",
    "    LLMQuery,\n",
    "    EnrichedEntitiesRelations\n",
    ")\n",
    "from backend.eval_config import YAGO_CONFIGS\n",
    "import networkx as nx\n",
    "config = YAGO_CONFIGS[-1]\n",
    "store = SPARQLStore(\n",
    "    config.sparql_endpoint,\n",
    "    method=\"POST_FORM\",\n",
    "    params={\"infer\": False, \"sameAs\": False},\n",
    ")\n",
    "graph = Graph(store=store)\n",
    "\n",
    "oconfig = OntologyConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLM model NousResearch/Hermes-3-Llama-3.2-3B-GGUF None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes\n",
      "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA GeForce RTX 4090) - 23528 MiB free\n",
      "llama_model_loader: loaded meta data with 38 key-value pairs and 255 tensors from /home/bkantz/.cache/huggingface/hub/models--NousResearch--Hermes-3-Llama-3.2-3B-GGUF/snapshots/3cd927095d8cbab12c743f932aa63b6f7bbfa141/./Hermes-3-Llama-3.2-3B.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Hermes 3 Llama 3.2 3b Base Fft Chatml...\n",
      "llama_model_loader: - kv   3:                            general.version str              = 2024-11-24\n",
      "llama_model_loader: - kv   4:                       general.organization str              = Nous Research Core\n",
      "llama_model_loader: - kv   5:                           general.finetune str              = base-fft-chatml-rerun-8xh100-e4-4k-steps\n",
      "llama_model_loader: - kv   6:                           general.basename str              = Hermes-3-Llama-3.2\n",
      "llama_model_loader: - kv   7:                         general.size_label str              = 3B\n",
      "llama_model_loader: - kv   8:                            general.license str              = llama3\n",
      "llama_model_loader: - kv   9:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv  10:                  general.base_model.0.name str              = Meta Llama 3.2 3B\n",
      "llama_model_loader: - kv  11:          general.base_model.0.organization str              = Meta Llama\n",
      "llama_model_loader: - kv  12:              general.base_model.0.repo_url str              = https://huggingface.co/meta-llama/Met...\n",
      "llama_model_loader: - kv  13:                               general.tags arr[str,12]      = [\"Llama-3\", \"instruct\", \"finetune\", \"...\n",
      "llama_model_loader: - kv  14:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv  15:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv  16:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  17:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  18:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  19:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  20:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  21:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  22:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  23:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  24:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  25:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  26:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  27:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  28:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  29:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  30:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  31:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  32:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  33:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  34:                tokenizer.ggml.eos_token_id u32              = 128039\n",
      "llama_model_loader: - kv  35:            tokenizer.ggml.padding_token_id u32              = 128001\n",
      "llama_model_loader: - kv  36:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
      "llama_model_loader: - kv  37:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q8_0:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q8_0\n",
      "print_info: file size   = 3.18 GiB (8.50 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128040 '<|im_start|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7994 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_swa_pattern    = 1\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Hermes 3 Llama 3.2 3b Base Fft Chatml Rerun 8xh100 E4 2024 11 24 4k Steps\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128039 '<|im_end|>'\n",
      "print_info: EOT token        = 128039 '<|im_end|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: PAD token        = 128001 '<|end_of_text|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: EOG token        = 128039 '<|im_end|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q8_0) (and 0 others) cannot be used with preferred buffer type CUDA_Host, using CPU instead\n",
      "load_tensors: offloading 28 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 29/29 layers to GPU\n",
      "load_tensors:        CUDA0 model buffer size =  3255.90 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =   399.23 MiB\n",
      ".................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 10000\n",
      "llama_context: n_ctx_per_seq = 10000\n",
      "llama_context: n_batch       = 2048\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (10000) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 10016 (padded)\n",
      "llama_kv_cache_unified: kv_size = 10016, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1, padding = 32\n",
      "llama_kv_cache_unified: layer   0: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   1: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   2: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   3: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   4: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   5: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   6: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   7: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   8: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   9: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  10: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  11: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  12: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  13: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  14: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  15: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  16: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  17: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  18: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  19: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  20: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  21: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  22: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  23: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  24: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  25: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  26: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  27: dev = CUDA0\n",
      "llama_kv_cache_unified:      CUDA0 KV buffer size =  1095.50 MiB\n",
      "llama_kv_cache_unified: KV self size  = 1095.50 MiB, K (f16):  547.75 MiB, V (f16):  547.75 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 2\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context:      CUDA0 compute buffer size =   513.07 MiB\n",
      "llama_context:  CUDA_Host compute buffer size =    25.57 MiB\n",
      "llama_context: graph nodes  = 958\n",
      "llama_context: graph splits = 2\n",
      "CUDA : ARCHS = 890 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | AVX512_BF16 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'tokenizer.ggml.padding_token_id': '128001', 'general.license': 'llama3', 'llama.attention.value_length': '128', 'general.size_label': '3B', 'general.type': 'model', 'general.organization': 'Nous Research Core', 'general.base_model.0.repo_url': 'https://huggingface.co/meta-llama/Meta-Llama-3.2-3B', 'general.version': '2024-11-24', 'general.base_model.0.name': 'Meta Llama 3.2 3B', 'llama.rope.dimension_count': '128', 'llama.context_length': '131072', 'llama.embedding_length': '3072', 'general.basename': 'Hermes-3-Llama-3.2', 'general.architecture': 'llama', 'llama.attention.head_count_kv': '8', 'general.base_model.count': '1', 'general.base_model.0.organization': 'Meta Llama', 'llama.feed_forward_length': '8192', 'general.name': 'Hermes 3 Llama 3.2 3b Base Fft Chatml Rerun 8xh100 E4 2024 11 24 4k Steps', 'tokenizer.ggml.bos_token_id': '128000', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.eos_token_id': '128039', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.block_count': '28', 'llama.attention.head_count': '24', 'llama.attention.key_length': '128', 'general.finetune': 'base-fft-chatml-rerun-8xh100-e4-4k-steps', 'general.file_type': '7', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.vocab_size': '128256', 'tokenizer.ggml.model': 'gpt2'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "ontology_manager = OntologyManager(oconfig, graph)\n",
    "topic_man = GuidanceManager(\n",
    "    conn_str=config.conn_str,\n",
    "    oman=ontology_manager,\n",
    "    llm_model_id=config.model_id,\n",
    ")\n",
    "llama_model = topic_man.llama_model\n",
    "querier = LLMQuery(topic=topic_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 219 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =      70.25 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =     900.84 ms /   171 runs   (    5.27 ms per token,   189.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    2136.79 ms /   172 tokens\n",
      "Llama.generate: 219 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =      70.25 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =     889.94 ms /   171 runs   (    5.20 ms per token,   192.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    2122.13 ms /   172 tokens\n"
     ]
    }
   ],
   "source": [
    "final_progress = querier.run_query(\"A scholarly article is depicted by an image object\", enable_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f29c732bb00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def viz_graph(erl: EnrichedEntitiesRelations):\n",
    "    G = nx.DiGraph()\n",
    "    for node in erl.entities:\n",
    "        G.add_node(node.identifier, label=node.type)\n",
    "    for link in erl.relations:\n",
    "        G.add_edge(\n",
    "            link.entity,\n",
    "            link.target,\n",
    "            # weight=link.link.instance_count,\n",
    "            label=link.relation,\n",
    "        )\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw_networkx(\n",
    "        G,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        labels={node.identifier: node.type for node in erl.entities},\n",
    "    )\n",
    "    nx.draw_networkx_edge_labels(\n",
    "        G,\n",
    "        pos,\n",
    "        edge_labels={\n",
    "            (link.entity, link.target): link.relation for link in erl.relations\n",
    "        },\n",
    "    )\n",
    "    return G\n",
    "\n",
    "\n",
    "viz_graph(final_progress.enriched_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image object', 'scholarly article']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    ent.identifier for ent in final_progress.enriched_relations.entities\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('image object', 'scholarly article')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_progress.enriched_relations.relations[0].entity, final_progress.enriched_relations.relations[0].target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(final_progress.relations_steps[-2].entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_progress.enriched_relations.entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
