{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))\n",
    "sys.path.append(os.path.abspath(\"../../backend\"))\n",
    "sys.path.append(os.path.abspath(\"\"))\n",
    "\n",
    "from sqlalchemy.orm import aliased, joinedload, selectinload, contains_eager\n",
    "from sqlalchemy import text\n",
    "from rdflib.plugins.stores.sparqlstore import SPARQLStore\n",
    "from backend.model import (\n",
    "    DeclarativeBase,\n",
    "    Session,\n",
    ")\n",
    "\n",
    "from backend.ontology import OntologyManager, OntologyConfig, Graph\n",
    "from backend.explorative_support import TopicModelling, select\n",
    "from backend.llm_query import (\n",
    "    Entity,\n",
    "    Relation,\n",
    "    EntitiesRelations,\n",
    "    EnrichedEntity,\n",
    "    EnrichedRelation,\n",
    "    EnrichedEntitiesRelations,\n",
    "    SubjectLink,\n",
    "    SubjectInDB,\n",
    "    SubjectLinkDB,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "store = SPARQLStore(\n",
    "    \"http://localhost:7012/\",\n",
    "    method=\"POST_FORM\",\n",
    "    params={\"infer\": False, \"sameAs\": False},\n",
    ")\n",
    "graph = Graph(store=store)\n",
    "\n",
    "config = OntologyConfig()\n",
    "\n",
    "ontology_manager = OntologyManager(config, graph)\n",
    "topic_man = TopicModelling(ontology_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 100\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from educational institution school on link alma mater\n",
      "Extending to populated place extending_to False\n",
      "Downgraded from broadcaster radio station on link broadcast area\n",
      "Extending to populated place extending_to True\n",
      "Downgraded from person athlete on link leader name\n",
      "Extending to person extending_to True\n",
      "Downgraded from military service military service on link military service\n",
      "Extending to person extending_to False\n",
      "Downgraded from work album on link auteur\n",
      "Extending to radio station extending_to True\n",
      "Extending to populated place extending_to False\n",
      "Downgraded from river river on link mouth place\n",
      "Extending to person extending_to True\n",
      "Downgraded from career station career station on link career station\n",
      "Extending to career station extending_to False\n",
      "Downgraded from person Sports team member on link career station\n"
     ]
    }
   ],
   "source": [
    "from typing import TypeVar\n",
    "\n",
    "SL = TypeVar(\"SL\")\n",
    "\n",
    "\n",
    "class EnrichedDBEntity(Entity, arbitrary_types_allowed=True):\n",
    "    subject: SubjectInDB\n",
    "\n",
    "\n",
    "class EnrichedDBRelation(Relation, arbitrary_types_allowed=True):\n",
    "    link: SubjectLinkDB\n",
    "\n",
    "\n",
    "def safe_prob(probs: np.array):\n",
    "    if np.sum(probs) == 0:\n",
    "        return np.ones(len(probs)) / len(probs)\n",
    "    else:\n",
    "        return probs / probs.sum()\n",
    "\n",
    "\n",
    "def choose_entity(links: list[SL], rs: np.random.RandomState) -> SL:\n",
    "    probs = np.array([link.instance_count for link in links])\n",
    "    probs = safe_prob(probs)\n",
    "    indices = np.arange(len(links))\n",
    "    choice = rs.choice(indices, p=probs)\n",
    "    return links[choice]\n",
    "\n",
    "\n",
    "def random_downgrade(cls: SubjectInDB, rs: np.random.RandomState) -> SubjectInDB:\n",
    "    def get_subclasses(subcls: SubjectInDB):\n",
    "        subclasses = [subcls.sub_classes] + [\n",
    "            get_subclasses(sub) for sub in subcls.sub_classes\n",
    "        ]\n",
    "        return [sub for sublist in subclasses for sub in sublist]\n",
    "\n",
    "    # print(f\"downgrading {cls.label}\", [sc.label for sc in cls.sub_classes])\n",
    "    subclasses = [cls] + get_subclasses(cls)\n",
    "    probs = np.array([float(sc.instance_count) for sc in subclasses])\n",
    "    probs = safe_prob(probs)\n",
    "    # print(f\"{cls.label} probs\", probs)\n",
    "    choice = rs.choice(np.arange(len(subclasses)), p=probs)\n",
    "    return subclasses[choice]\n",
    "\n",
    "\n",
    "def choose_graph(max_nodes=4, top_k=top_k, seed=seed, max_tries=5):\n",
    "    rs = np.random.RandomState(seed)\n",
    "    with Session(topic_man.engine) as session:\n",
    "        session.execute(text(\"SET TRANSACTION READ ONLY\"))\n",
    "        session.autoflush = False\n",
    "\n",
    "        def downgrade_link_subjects(link: SubjectLinkDB):\n",
    "            from_downgrade = random_downgrade(link.from_subject, rs)\n",
    "            to_downgrade = random_downgrade(link.to_subject, rs)\n",
    "            link.from_id = from_downgrade.subject_id\n",
    "            link.to_id = to_downgrade.subject_id\n",
    "            link.from_subject = from_downgrade\n",
    "            link.to_subject = to_downgrade\n",
    "            return link\n",
    "\n",
    "        from_subject_alias = aliased(SubjectInDB, name=\"from_subject\")\n",
    "        to_subject_alias = aliased(SubjectInDB, name=\"to_subject\")\n",
    "        best_links_db = session.execute(\n",
    "            select(SubjectLinkDB)\n",
    "            .filter(SubjectLinkDB.from_id != SubjectLinkDB.to_id)\n",
    "            .filter(SubjectLinkDB.to_id != None)\n",
    "            .order_by(SubjectLinkDB.instance_count.desc())\n",
    "            .join(\n",
    "                from_subject_alias,\n",
    "                SubjectLinkDB.from_subject.of_type(from_subject_alias),\n",
    "            )\n",
    "            .join(to_subject_alias, SubjectLinkDB.to_subject.of_type(to_subject_alias))\n",
    "            # .options(\n",
    "            #     lazyload(SubjectLinkDB.from_subject.of_type(from_subject_alias)),\n",
    "            #     lazyload(SubjectLinkDB.to_subject.of_type(to_subject_alias)),\n",
    "            # )\n",
    "            .limit(top_k)\n",
    "        ).all()\n",
    "        best_links: list[SubjectLinkDB] = [link[0] for link in best_links_db]\n",
    "        choice = choose_entity(best_links, rs)\n",
    "        choice_downgraded = downgrade_link_subjects(choice)\n",
    "\n",
    "        current_links = [\n",
    "            (\n",
    "                EnrichedDBRelation(\n",
    "                    entity=choice_downgraded.from_subject.label,\n",
    "                    relation=choice.label,\n",
    "                    target=choice_downgraded.to_subject.label,\n",
    "                    link=choice_downgraded,\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        current_nodes = {\n",
    "            subject.label: EnrichedDBEntity(\n",
    "                identifier=subject.label,\n",
    "                type=subject.label,\n",
    "                subject=subject,\n",
    "            )\n",
    "            for subject in [\n",
    "                choice_downgraded.from_subject,\n",
    "                choice_downgraded.to_subject,\n",
    "            ]\n",
    "        }\n",
    "        retries = 0\n",
    "        while len(current_nodes) < max_nodes:\n",
    "            start_node = choose_entity(\n",
    "                list([nd.subject for nd in current_nodes.values()]), rs\n",
    "            )\n",
    "            left_right = rs.choice([0, 1])\n",
    "            extending_to = left_right == 0\n",
    "            query = (\n",
    "                select(SubjectLinkDB)\n",
    "                .where(SubjectLinkDB.from_id != SubjectLinkDB.to_id)\n",
    "                .where(SubjectLinkDB.to_id is not None)\n",
    "                .join(\n",
    "                    from_subject_alias,\n",
    "                    SubjectLinkDB.from_subject.of_type(from_subject_alias),\n",
    "                )\n",
    "                .join(\n",
    "                    to_subject_alias, SubjectLinkDB.to_subject.of_type(to_subject_alias)\n",
    "                )\n",
    "                .filter(\n",
    "                    SubjectLinkDB.link_id.not_in(\n",
    "                        [link.link.link_id for link in current_links]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            if extending_to:\n",
    "                query = query.where(SubjectLinkDB.from_id == start_node.subject_id)\n",
    "            else:\n",
    "                query = query.where(SubjectLinkDB.to_id == start_node.subject_id)\n",
    "            print(\"Extending to\", start_node.label, \"extending_to\", extending_to)\n",
    "            new_links = session.execute(\n",
    "                query.order_by(SubjectLinkDB.instance_count.desc()).limit(top_k)\n",
    "            ).all()\n",
    "            new_links: list[SubjectLinkDB] = [link[0] for link in new_links]\n",
    "            if len(new_links) == 0:\n",
    "                if retries >= max_tries:\n",
    "                    break\n",
    "                retries += 1\n",
    "                continue\n",
    "            choice = choose_entity(new_links, rs)\n",
    "\n",
    "            extending_direction = (\n",
    "                (choice.from_subject, choice.to_subject)\n",
    "                if extending_to\n",
    "                else (choice.to_subject, choice.from_subject)\n",
    "            )\n",
    "\n",
    "            downgraded_extend = random_downgrade(extending_direction[1], rs)\n",
    "            print(\n",
    "                \"Downgraded from\",\n",
    "                extending_direction[1].label,\n",
    "                downgraded_extend.label,\n",
    "                \"on link\",\n",
    "                choice.label,\n",
    "            )\n",
    "            if extending_to:\n",
    "                choice_downgraded.to_id = downgraded_extend.subject_id\n",
    "                choice_downgraded.to_subject = downgraded_extend\n",
    "            else:\n",
    "                choice_downgraded.from_id = downgraded_extend.subject_id\n",
    "                choice_downgraded.from_subject = downgraded_extend\n",
    "            if extending_to:\n",
    "                current_links.append(\n",
    "                    EnrichedDBRelation(\n",
    "                        entity=choice.from_subject.label,\n",
    "                        relation=choice.label,\n",
    "                        target=choice_downgraded.to_subject.label,\n",
    "                        link=choice_downgraded,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                current_links.append(\n",
    "                    EnrichedDBRelation(\n",
    "                        entity=choice_downgraded.from_subject.label,\n",
    "                        relation=choice.label,\n",
    "                        target=choice.to_subject.label,\n",
    "                        link=choice_downgraded,\n",
    "                    )\n",
    "                )\n",
    "            current_nodes.update(\n",
    "                {\n",
    "                    subject.label: EnrichedDBEntity(\n",
    "                        identifier=subject.label,\n",
    "                        type=subject.label,\n",
    "                        subject=subject,\n",
    "                    )\n",
    "                    for subject in [extending_direction[0], downgraded_extend]\n",
    "                }\n",
    "            )\n",
    "        enriched_erl = EnrichedEntitiesRelations(\n",
    "            entities=[\n",
    "                EnrichedEntity(\n",
    "                    subject=ontology_manager.enrich_subject(entity.subject.subject_id),\n",
    "                    **entity.model_dump(exclude=[\"subject\"]),\n",
    "                )\n",
    "                for entity in current_nodes.values()\n",
    "            ],\n",
    "            relations=[\n",
    "                EnrichedRelation(\n",
    "                    link=SubjectLink.from_db(relation.link, ontology_manager),\n",
    "                    **relation.model_dump(exclude=[\"link\"]),\n",
    "                )\n",
    "                for relation in current_links\n",
    "            ],\n",
    "        )\n",
    "        return enriched_erl\n",
    "\n",
    "\n",
    "erl = choose_graph(seed=33, max_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('person', 'birth place', 'populated place'),\n",
       " ('person', 'alma mater', 'school'),\n",
       " ('radio station', 'broadcast area', 'populated place'),\n",
       " ('populated place', 'leader name', 'athlete'),\n",
       " ('person', 'military service', 'military service'),\n",
       " ('album', 'auteur', 'person'),\n",
       " ('river', 'mouth place', 'populated place'),\n",
       " ('person', 'career station', 'career station'),\n",
       " ('Sports team member', 'career station', 'career station')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(link.entity, link.relation, link.target) for link in erl.relations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"identifier\":\"person\",\"type\":\"person\",\"constraints\":[],\"subject\":{\"subject_id\":\"<http://dbpedia.org/ontology/Person>\",\"label\":\"person\",\"spos\":{\"rdfs:label\":{\"property\":\"rdfs:label\",\"label\":null,\"values\":[{\"value\":\"person\",\"label\":null}]},\"rdfs:subClassOf\":{\"property\":\"rdfs:subClassOf\",\"label\":null,\"values\":[{\"value\":\"<http://dbpedia.org/ontology/Animal>\",\"label\":\"animal\"}]}},\"subject_type\":\"class\",\"refcount\":0,\"descendants\":{},\"total_descendants\":0,\"properties\":{},\"instance_count\":1922501}}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erl.entities[0].model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f0e24310b00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "def viz_graph(erl: EnrichedEntitiesRelations):\n",
    "    G = nx.DiGraph()\n",
    "    for node in erl.entities:\n",
    "        G.add_node(node.identifier, label=node.type)\n",
    "    for link in erl.relations:\n",
    "        G.add_edge(\n",
    "            link.entity, link.target, weight=link.link.instance_count, label=link.relation\n",
    "        )\n",
    "    pos = nx.shell_layout(G)\n",
    "    nx.draw_networkx(\n",
    "        G,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        labels={node.identifier: node.type for node in erl.entities},\n",
    "    )\n",
    "    nx.draw_networkx_edge_labels(\n",
    "        G, pos, edge_labels={(link.entity, link.target): link.relation for link in erl.relations}\n",
    "    )\n",
    "    return G\n",
    "\n",
    "\n",
    "viz_graph(erl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    yes\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes\n",
      "llama_load_model_from_file: using device CUDA0 (NVIDIA GeForce RTX 4090) - 23307 MiB free\n",
      "llama_model_loader: loaded meta data with 27 key-value pairs and 292 tensors from /home/bkantz/.cache/huggingface/hub/models--NousResearch--Hermes-3-Llama-3.1-8B-GGUF/snapshots/307a5dfb59aa38d88b6cfd32f44b8ad7c1da9fb8/./Hermes-3-Llama-3.1-8B.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Hermes 3 Llama 3.1 8B\n",
      "llama_model_loader: - kv   3:                       general.organization str              = NousResearch\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Hermes-3-Llama-3.1\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   7:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   8:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   9:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  10:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  11:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  13:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = [\" \", \" \", \" \", \"...\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128040\n",
      "llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 128040\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   66 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128039 '<|im_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7994 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 7.95 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Hermes 3 Llama 3.1 8B\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128040 '<|im_end|>'\n",
      "llm_load_print_meta: EOT token        = 128040 '<|im_end|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: PAD token        = 128040 '<|im_end|>'\n",
      "llm_load_print_meta: LF token         = 128 ''\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOG token        = 128040 '<|im_end|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q8_0) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading output layer to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CUDA0 model buffer size =  7605.33 MiB\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =   532.31 MiB\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 10016\n",
      "llama_new_context_with_model: n_ctx_per_seq = 10016\n",
      "llama_new_context_with_model: n_batch       = 1024\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 500000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (10016) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1252.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1252.00 MiB, K (f16):  626.00 MiB, V (f16):  626.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   677.57 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    27.57 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | FORCE_MMQ = 1 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128040', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '7', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.padding_token_id': '128040', 'general.basename': 'Hermes-3-Llama-3.1', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Hermes 3 Llama 3.1 8B', 'general.organization': 'NousResearch', 'general.type': 'model', 'general.size_label': '8B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "llama_model = topic_man.llama_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\"You are a helpful assistant turning relational knowledge into natural language.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": EntitiesRelations(\n",
    "            entities=[\n",
    "                Entity(\n",
    "                    identifier=\"person 1\",\n",
    "                    type=\"person\",\n",
    "                ),\n",
    "                Entity(\n",
    "                    identifier=\"place 1\",\n",
    "                    type=\"place\",\n",
    "                ),\n",
    "                Entity(\n",
    "                    identifier=\"company 1\",\n",
    "                    type=\"person\",\n",
    "                ),\n",
    "            ],\n",
    "            relations=[\n",
    "                Relation(\n",
    "                    entity=\"company 1\",\n",
    "                    relation=\"employs\",\n",
    "                    target=\"person 1\",\n",
    "                ),\n",
    "                Relation(\n",
    "                    entity=\"person 1\",\n",
    "                    relation=\"residence\",\n",
    "                    target=\"place 1\",\n",
    "                ),\n",
    "            ],\n",
    "        ).model_dump_json(),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"a person is employed by a company and the same person resides in a place\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  4906 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    80 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2105.09 ms /  4986 tokens\n"
     ]
    }
   ],
   "source": [
    "response = llama_model.create_chat_completion(\n",
    "    # grammar=self.grammar_erl,\n",
    "    messages=messages + [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": erl.model_dump_json(),\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=-1,\n",
    "    temperature=0.7,  # get wild :)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a person is born in a populated place, attends a school, is employed by a radio station, is led by an athlete, serves in military service, creates an album, ends in a river, is in a career station, is a sports team member, and is related to a career station. Additionally, a populated place has a leader named an athlete, and a river has a mouth place.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/900 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Organisation member extending_to False\n",
      "Downgraded from organisation company on link organisation member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1143 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1143 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    46 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     700.79 ms /  1189 tokens\n",
      "  0%|          | 1/900 [00:01<21:35,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to written work extending_to False\n",
      "Downgraded from multi volume publication multi volume publication on link volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1152 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1152 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     361.06 ms /  1170 tokens\n",
      "  0%|          | 2/900 [00:02<16:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to True\n",
      "Downgraded from person person on link auteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1090 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1090 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     327.57 ms /  1105 tokens\n",
      "  0%|          | 3/900 [00:03<14:50,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Organisation member extending_to False\n",
      "Downgraded from organisation organisation on link organisation member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1212 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1212 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.53 ms /  1225 tokens\n",
      "  0%|          | 4/900 [00:04<14:37,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Sports team member extending_to True\n",
      "Extending to Sports team member extending_to True\n",
      "Extending to Sports team member extending_to True\n",
      "Extending to Sports team member extending_to False\n",
      "Extending to Sports team member extending_to True\n",
      "Extending to Sports team member extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 677 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   677 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     267.01 ms /   690 tokens\n",
      "  1%|          | 5/900 [00:04<13:39,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to place extending_to True\n",
      "Downgraded from person function person function on link political leader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1120 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1120 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     330.86 ms /  1136 tokens\n",
      "  1%|          | 6/900 [00:05<14:21,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to route of transportation extending_to True\n",
      "Downgraded from station station on link route end\n",
      "Extending to station extending_to True\n",
      "Extending to route of transportation extending_to True\n",
      "Downgraded from station station on link route end\n",
      "Extending to route of transportation extending_to True\n",
      "Downgraded from station station on link route junction\n",
      "Extending to station extending_to False\n",
      "Downgraded from route of transportation road on link route junction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 2207 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  2207 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     635.65 ms /  2236 tokens\n",
      "  1%|          | 7/900 [00:07<15:56,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 673 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   673 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     507.59 ms /   707 tokens\n",
      "  1%|          | 8/900 [00:08<15:16,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to politician extending_to True\n",
      "Downgraded from person Organisation member on link prefect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1171 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1171 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     477.42 ms /  1198 tokens\n",
      "  1%|          | 9/900 [00:09<15:19,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to False\n",
      "Downgraded from sports event soccer tournoment on link champion in double male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1198 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1198 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.96 ms /  1217 tokens\n",
      "  1%|          | 10/900 [00:10<14:55,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to False\n",
      "Downgraded from television show television show on link opening theme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1287 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1287 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    46 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     722.68 ms /  1333 tokens\n",
      "  1%|          | 11/900 [00:11<15:44,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to person extending_to True\n",
      "Downgraded from educational institution school on link alma mater\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1149 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1149 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     447.80 ms /  1174 tokens\n",
      "  1%|         | 12/900 [00:12<16:31,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 758 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   758 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     241.29 ms /   770 tokens\n",
      "  1%|         | 13/900 [00:13<14:15,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to True\n",
      "Downgraded from agent sports club on link producer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1106 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1106 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     312.67 ms /  1121 tokens\n",
      "  2%|         | 14/900 [00:14<13:37,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to cricket team extending_to True\n",
      "Extending to winter sport Player extending_to False\n",
      "Extending to winter sport Player extending_to True\n",
      "Extending to winter sport Player extending_to True\n",
      "Extending to winter sport Player extending_to False\n",
      "Extending to winter sport Player extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 678 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   678 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     257.83 ms /   692 tokens\n",
      "  2%|         | 15/900 [00:14<13:02,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from athlete athlete on link trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1136 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    39 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     622.85 ms /  1175 tokens\n",
      "  2%|         | 16/900 [00:16<14:36,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work work on link author\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 143 prefix-match hit, remaining 1099 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1099 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    37 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.24 ms /  1136 tokens\n",
      "  2%|         | 17/900 [00:17<16:01,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from career station career station on link career station\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 148 prefix-match hit, remaining 1129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1129 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.09 ms /  1142 tokens\n",
      "  2%|         | 18/900 [00:18<15:18,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to musical work extending_to True\n",
      "Downgraded from agent agent on link performer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1140 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    28 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     482.32 ms /  1168 tokens\n",
      "  2%|         | 19/900 [00:19<14:57,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to musical artist extending_to True\n",
      "Downgraded from Band Band on link Music Band\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 141 prefix-match hit, remaining 1410 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1410 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     546.73 ms /  1441 tokens\n",
      "  2%|         | 20/900 [00:20<15:41,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to song extending_to False\n",
      "Extending to song extending_to True\n",
      "Extending to song extending_to True\n",
      "Extending to song extending_to True\n",
      "Extending to song extending_to True\n",
      "Extending to song extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 687 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   687 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     219.59 ms /   698 tokens\n",
      "  2%|         | 21/900 [00:21<14:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from place place on link residence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1106 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1106 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     413.36 ms /  1128 tokens\n",
      "  2%|         | 22/900 [00:22<14:34,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team sports team on link debut team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1153 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     558.75 ms /  1187 tokens\n",
      "  3%|         | 23/900 [00:23<15:12,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Australian rules football player extending_to True\n",
      "Extending to Australian rules football player extending_to True\n",
      "Extending to hockey team extending_to True\n",
      "Extending to Australian rules football player extending_to True\n",
      "Extending to Australian rules football player extending_to False\n",
      "Extending to Australian rules football player extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 685 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   685 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     247.46 ms /   699 tokens\n",
      "  3%|         | 24/900 [00:24<13:24,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to river extending_to False\n",
      "Downgraded from body of water river on link outflow\n",
      "Extending to river extending_to False\n",
      "Downgraded from bridge bridge on link crosses\n",
      "Extending to river extending_to False\n",
      "Downgraded from body of water lake on link outflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1835 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1835 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    76 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1158.90 ms /  1911 tokens\n",
      "  3%|         | 25/900 [00:25<17:14,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to True\n",
      "Downgraded from city city on link capital\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1142 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1142 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     436.32 ms /  1166 tokens\n",
      "  3%|         | 26/900 [00:26<16:13,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to True\n",
      "Downgraded from populated place populated place on link federal state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1158 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1158 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     326.61 ms /  1173 tokens\n",
      "  3%|         | 27/900 [00:27<15:41,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to album extending_to False\n",
      "Extending to album extending_to True\n",
      "Downgraded from single list single list on link list of singles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1135 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1135 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    48 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     729.51 ms /  1183 tokens\n",
      "  3%|         | 28/900 [00:28<15:59,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person function extending_to True\n",
      "Downgraded from person person on link person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1150 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1150 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     413.03 ms /  1172 tokens\n",
      "  3%|         | 29/900 [00:30<15:44,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to place extending_to False\n",
      "Downgraded from animal person on link birth place\n",
      "Extending to place extending_to True\n",
      "Downgraded from populated place settlement on link nearest city\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1487 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1487 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     514.13 ms /  1514 tokens\n",
      "  3%|         | 30/900 [00:31<16:21,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work musical work on link author\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 143 prefix-match hit, remaining 1160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1160 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     563.73 ms /  1193 tokens\n",
      "  3%|         | 31/900 [00:32<16:37,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to True\n",
      "Downgraded from populated place populated place on link federal state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1195 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1195 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     527.68 ms /  1226 tokens\n",
      "  4%|         | 32/900 [00:33<16:54,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to office holder extending_to True\n",
      "Downgraded from political party political party on link other party\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1133 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    39 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     621.31 ms /  1172 tokens\n",
      "  4%|         | 33/900 [00:34<16:58,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from educational institution school on link alma mater\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1147 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1147 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    65 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.50 ms /  1212 tokens\n",
      "  4%|         | 34/900 [00:36<18:31,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 673 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   673 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     307.93 ms /   691 tokens\n",
      "  4%|         | 35/900 [00:37<16:09,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to False\n",
      "Downgraded from television show television show on link opening theme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1133 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     433.45 ms /  1156 tokens\n",
      "  4%|         | 36/900 [00:37<15:03,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to stream extending_to False\n",
      "Extending to stream extending_to True\n",
      "Downgraded from country country on link source country\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1148 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1148 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     421.30 ms /  1171 tokens\n",
      "  4%|         | 37/900 [00:38<14:26,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to mountain extending_to False\n",
      "Downgraded from river river on link mouth mountain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1156 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1156 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     332.70 ms /  1172 tokens\n",
      "  4%|         | 38/900 [00:39<13:08,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to village extending_to False\n",
      "Extending to village extending_to True\n",
      "Extending to village extending_to False\n",
      "Extending to village extending_to True\n",
      "Extending to village extending_to False\n",
      "Extending to village extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 677 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   677 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     205.14 ms /   687 tokens\n",
      "  4%|         | 39/900 [00:40<12:22,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to True\n",
      "Downgraded from populated place region on link frazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1151 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1151 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     323.03 ms /  1166 tokens\n",
      "  4%|         | 40/900 [00:41<13:08,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to True\n",
      "Downgraded from musical artist musical artist on link music composer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1241 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1241 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     628.09 ms /  1279 tokens\n",
      "  5%|         | 41/900 [00:42<13:39,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to False\n",
      "Extending to settlement extending_to False\n",
      "Downgraded from agent educational institution on link home town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1180 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1180 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.11 ms /  1200 tokens\n",
      "  5%|         | 42/900 [00:43<14:20,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to True\n",
      "Downgraded from populated place populated place on link federal state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1195 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1195 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     442.39 ms /  1219 tokens\n",
      "  5%|         | 43/900 [00:44<14:43,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 674 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   674 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.10 ms /   686 tokens\n",
      "  5%|         | 44/900 [00:45<13:07,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to False\n",
      "Downgraded from television show television show on link opening theme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1163 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1163 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     489.01 ms /  1190 tokens\n",
      "  5%|         | 45/900 [00:46<13:12,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to False\n",
      "Downgraded from agent organisation on link home town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1131 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1131 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    62 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     896.39 ms /  1193 tokens\n",
      "  5%|         | 46/900 [00:47<15:13,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to False\n",
      "Downgraded from legislature legislature on link meeting city\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1179 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1179 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   106 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1442.18 ms /  1285 tokens\n",
      "  5%|         | 47/900 [00:49<18:47,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 682 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   682 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.26 ms /   700 tokens\n",
      "  5%|         | 48/900 [00:50<16:07,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 671 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   671 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     211.89 ms /   681 tokens\n",
      "  5%|         | 49/900 [00:50<13:59,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to False\n",
      "Extending to animal extending_to True\n",
      "Downgraded from place place on link death place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1113 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    37 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     591.21 ms /  1150 tokens\n",
      "  6%|         | 50/900 [00:52<15:20,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work book on link auteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1130 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1130 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    50 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     752.49 ms /  1180 tokens\n",
      "  6%|         | 51/900 [00:53<16:39,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to True\n",
      "Downgraded from person athlete on link trainer\n",
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team sports team on link manager club\n",
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team sports team on link debut team\n",
      "Extending to athlete extending_to False\n",
      "Downgraded from sports event sports event on link champion in double male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 2240 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  2240 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    94 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.55 ms /  2334 tokens\n",
      "  6%|         | 52/900 [00:55<21:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to military unit extending_to True\n",
      "Downgraded from person athlete on link notable commander\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1160 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     426.73 ms /  1183 tokens\n",
      "  6%|         | 53/900 [00:56<18:54,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to False\n",
      "Downgraded from language language on link spoken in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1123 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1123 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.12 ms /  1142 tokens\n",
      "  6%|         | 54/900 [00:57<17:37,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to artwork extending_to False\n",
      "Extending to artwork extending_to True\n",
      "Downgraded from museum museum on link museum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1138 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1138 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     274.51 ms /  1149 tokens\n",
      "  6%|         | 55/900 [00:58<15:17,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 682 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   682 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    30 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     463.30 ms /   712 tokens\n",
      "  6%|         | 56/900 [00:59<14:23,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from sports team sports team on link current member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1144 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    35 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     573.67 ms /  1179 tokens\n",
      "  6%|         | 57/900 [01:00<14:52,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from country country on link state of origin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 143 prefix-match hit, remaining 1142 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1142 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     304.98 ms /  1156 tokens\n",
      "  6%|         | 58/900 [01:01<14:01,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work work on link auteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 143 prefix-match hit, remaining 1114 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1114 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    41 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     636.36 ms /  1155 tokens\n",
      "  7%|         | 59/900 [01:02<15:42,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to place extending_to True\n",
      "Downgraded from populated place village on link district\n",
      "Extending to place extending_to True\n",
      "Downgraded from person function person function on link political leader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1413 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1413 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     369.99 ms /  1429 tokens\n",
      "  7%|         | 60/900 [01:03<14:47,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to False\n",
      "Extending to animal extending_to False\n",
      "Extending to animal extending_to True\n",
      "Downgraded from place town on link death place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1143 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1143 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    28 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     480.10 ms /  1171 tokens\n",
      "  7%|         | 61/900 [01:04<15:03,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to military person extending_to True\n",
      "Downgraded from military unit military unit on link military unit\n",
      "Extending to military unit extending_to False\n",
      "Downgraded from military person military person on link military unit\n",
      "Extending to military person extending_to True\n",
      "Downgraded from military unit military unit on link military unit\n",
      "Extending to military person extending_to True\n",
      "Downgraded from military unit military unit on link military unit\n",
      "Extending to military person extending_to False\n",
      "Extending to military unit extending_to False\n",
      "Downgraded from military person military person on link military unit\n",
      "Extending to military person extending_to True\n",
      "Downgraded from military unit military unit on link military unit\n",
      "Extending to military unit extending_to True\n",
      "Downgraded from person person on link notable commander\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 3300 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  3300 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     835.68 ms /  3332 tokens\n",
      "  7%|         | 62/900 [01:06<18:20,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 657 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   657 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     283.98 ms /   673 tokens\n",
      "  7%|         | 63/900 [01:07<15:48,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from educational institution university on link alma mater\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1181 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1181 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    45 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     692.48 ms /  1226 tokens\n",
      "  7%|         | 64/900 [01:08<16:47,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from movie movie on link film director\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 143 prefix-match hit, remaining 1125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1125 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     547.34 ms /  1158 tokens\n",
      "  7%|         | 65/900 [01:10<16:59,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to True\n",
      "Downgraded from place region on link death place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1173 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1173 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    97 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1318.89 ms /  1270 tokens\n",
      "  7%|         | 66/900 [01:12<20:06,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to person extending_to False\n",
      "Downgraded from work work on link auteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1122 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1122 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     464.82 ms /  1148 tokens\n",
      "  7%|         | 67/900 [01:13<18:28,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to False\n",
      "Downgraded from agent agent on link home town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1130 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1130 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    51 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     773.14 ms /  1181 tokens\n",
      "  8%|         | 68/900 [01:14<19:16,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to True\n",
      "Downgraded from place populated place on link death place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1169 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1169 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     442.10 ms /  1193 tokens\n",
      "  8%|         | 69/900 [01:15<18:03,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to True\n",
      "Downgraded from city city on link capital\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1132 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     340.33 ms /  1148 tokens\n",
      "  8%|         | 70/900 [01:16<16:44,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Organisation member extending_to False\n",
      "Downgraded from organisation organisation on link organisation member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1161 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     429.26 ms /  1184 tokens\n",
      "  8%|         | 71/900 [01:17<16:10,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from movie movie on link editing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1148 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1148 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     300.03 ms /  1161 tokens\n",
      "  8%|         | 72/900 [01:18<16:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to politician extending_to False\n",
      "Downgraded from political function political function on link politician\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1175 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1175 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     411.45 ms /  1197 tokens\n",
      "  8%|         | 73/900 [01:19<15:19,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to school extending_to True\n",
      "Downgraded from person person on link nobel laureates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1131 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1131 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    53 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     793.78 ms /  1184 tokens\n",
      "  8%|         | 74/900 [01:21<16:15,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 673 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   673 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     326.34 ms /   692 tokens\n",
      "  8%|         | 75/900 [01:22<14:22,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to True\n",
      "Downgraded from place populated place on link birth place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1167 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1167 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.60 ms /  1185 tokens\n",
      "  8%|         | 76/900 [01:23<14:16,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to True\n",
      "Downgraded from ethnic group ethnic group on link ethnic group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1276 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1276 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     350.35 ms /  1292 tokens\n",
      "  9%|         | 77/900 [01:24<14:06,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to river extending_to True\n",
      "Downgraded from mountain mountain on link mouth mountain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1143 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1143 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     416.29 ms /  1165 tokens\n",
      "  9%|         | 78/900 [01:24<13:21,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 664 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   664 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     218.57 ms /   675 tokens\n",
      "  9%|         | 79/900 [01:25<11:47,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to False\n",
      "Downgraded from sports event sports event on link champion in double female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1158 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1158 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     458.31 ms /  1184 tokens\n",
      "  9%|         | 80/900 [01:26<12:52,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from athlete soccer player on link trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1156 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1156 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     427.09 ms /  1179 tokens\n",
      "  9%|         | 81/900 [01:27<13:10,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to village extending_to False\n",
      "Extending to person extending_to False\n",
      "Downgraded from sports team sports team on link current member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1146 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    56 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     823.70 ms /  1202 tokens\n",
      "  9%|         | 82/900 [01:29<15:28,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team hockey team on link manager club\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1160 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     297.45 ms /  1173 tokens\n",
      "  9%|         | 83/900 [01:30<14:43,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to True\n",
      "Downgraded from populated place region on link federal state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1162 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1162 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.06 ms /  1180 tokens\n",
      "  9%|         | 84/900 [01:31<14:43,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to person extending_to False\n",
      "Downgraded from athlete soccer player on link trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1174 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1174 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    28 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     484.38 ms /  1202 tokens\n",
      "  9%|         | 85/900 [01:32<14:33,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to False\n",
      "Downgraded from sports event tournament on link champion in single male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1167 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1167 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    64 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     927.36 ms /  1231 tokens\n",
      " 10%|         | 86/900 [01:33<16:24,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 656 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   656 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    56 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     773.43 ms /   712 tokens\n",
      " 10%|         | 87/900 [01:34<16:15,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to book extending_to True\n",
      "Extending to soccer club extending_to True\n",
      "Downgraded from place settlement on link ground\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1152 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1152 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     372.83 ms /  1170 tokens\n",
      " 10%|         | 88/900 [01:35<15:24,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to musical work extending_to False\n",
      "Downgraded from military unit military unit on link march\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1177 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1177 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.32 ms /  1197 tokens\n",
      " 10%|         | 89/900 [01:36<14:38,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from career station career station on link career station\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1160 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     373.23 ms /  1178 tokens\n",
      " 10%|         | 90/900 [01:37<13:57,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to person extending_to True\n",
      "Downgraded from country country on link nationality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1145 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     348.69 ms /  1162 tokens\n",
      " 10%|         | 91/900 [01:38<13:23,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from country country on link nationality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 1283 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    30 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.71 ms /    31 tokens\n",
      " 10%|         | 92/900 [01:39<13:10,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team sports team on link former team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1155 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     425.14 ms /  1178 tokens\n",
      " 10%|         | 93/900 [01:40<13:06,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from sports team sports team on link current member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1146 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     682.41 ms /  1190 tokens\n",
      " 10%|         | 94/900 [01:41<14:24,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to movie extending_to False\n",
      "Downgraded from film festival film festival on link opening film\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1199 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1199 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     340.21 ms /  1215 tokens\n",
      " 11%|         | 95/900 [01:42<13:59,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to False\n",
      "Extending to animal extending_to True\n",
      "Downgraded from place populated place on link death place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1169 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1169 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     541.39 ms /  1201 tokens\n",
      " 11%|         | 96/900 [01:44<14:48,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to True\n",
      "Downgraded from populated place settlement on link frazioni\n",
      "Extending to settlement extending_to True\n",
      "Downgraded from populated place populated place on link frazioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1551 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1551 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    35 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.08 ms /  1586 tokens\n",
      " 11%|         | 97/900 [01:45<15:49,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to company extending_to False\n",
      "Downgraded from record label record label on link distributing company\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1150 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1150 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.58 ms /  1171 tokens\n",
      " 11%|         | 98/900 [01:46<14:33,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person function extending_to False\n",
      "Downgraded from organisation organisation on link leaderFunction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1123 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1123 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     454.55 ms /  1149 tokens\n",
      " 11%|         | 99/900 [01:47<14:21,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to baseball player extending_to False\n",
      "Extending to baseball player extending_to False\n",
      "Extending to baseball player extending_to False\n",
      "Extending to baseball player extending_to True\n",
      "Extending to baseball player extending_to True\n",
      "Extending to baseball player extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 680 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   680 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     379.26 ms /   703 tokens\n",
      " 11%|         | 100/900 [01:48<12:47,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to True\n",
      "Downgraded from city city on link capital\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1148 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1148 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.51 ms /  1167 tokens\n",
      " 11%|         | 101/900 [01:49<13:11,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work work on link author\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1112 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1112 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    56 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     821.64 ms /  1168 tokens\n",
      " 11%|        | 102/900 [01:50<15:11,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from sports team sports team on link current member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1140 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     438.85 ms /  1164 tokens\n",
      " 11%|        | 103/900 [01:51<14:53,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to False\n",
      "Downgraded from television show television show on link opening theme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1133 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     390.84 ms /  1153 tokens\n",
      " 12%|        | 104/900 [01:52<13:44,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from place place on link place of burial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1107 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     456.95 ms /  1134 tokens\n",
      " 12%|        | 105/900 [01:53<13:59,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from country country on link state of origin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 196 prefix-match hit, remaining 1089 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1089 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     262.84 ms /  1100 tokens\n",
      " 12%|        | 106/900 [01:54<12:52,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 682 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   682 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     608.16 ms /   726 tokens\n",
      " 12%|        | 107/900 [01:55<12:59,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 758 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   758 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    71 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.76 ms /   829 tokens\n",
      " 12%|        | 108/900 [01:56<14:21,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to True\n",
      "Downgraded from place place on link death place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1114 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1114 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     299.00 ms /  1128 tokens\n",
      " 12%|        | 109/900 [01:57<13:23,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to musical work extending_to True\n",
      "Downgraded from agent organisation on link performer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1155 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    45 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     674.60 ms /  1200 tokens\n",
      " 12%|        | 110/900 [01:58<14:32,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to Organisation member extending_to True\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 674 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   674 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     234.62 ms /   687 tokens\n",
      " 12%|        | 111/900 [01:59<12:43,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team sports team on link former team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1105 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    76 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.41 ms /  1181 tokens\n",
      " 12%|        | 112/900 [02:01<15:18,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to False\n",
      "Downgraded from sports event sports event on link champion in single male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1161 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     376.51 ms /  1181 tokens\n",
      " 13%|        | 113/900 [02:02<14:33,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work musical work on link auteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1160 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     531.16 ms /  1193 tokens\n",
      " 13%|        | 114/900 [02:03<14:27,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to winter sport Player extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 676 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   676 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    55 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     737.38 ms /   731 tokens\n",
      " 13%|        | 115/900 [02:04<14:30,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 664 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   664 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     280.37 ms /   681 tokens\n",
      " 13%|        | 116/900 [02:05<12:43,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work software on link auteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1129 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     276.47 ms /  1141 tokens\n",
      " 13%|        | 117/900 [02:06<12:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to False\n",
      "Downgraded from television show television show on link ending theme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1133 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     338.86 ms /  1150 tokens\n",
      " 13%|        | 118/900 [02:06<11:50,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person function extending_to False\n",
      "Downgraded from person politician on link person function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1133 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     505.96 ms /  1164 tokens\n",
      " 13%|        | 119/900 [02:07<12:34,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team sports team on link former team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1145 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.32 ms /  1166 tokens\n",
      " 13%|        | 120/900 [02:08<12:14,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to basketball player extending_to True\n",
      "Extending to basketball player extending_to False\n",
      "Extending to basketball team extending_to False\n",
      "Extending to basketball player extending_to True\n",
      "Extending to basketball player extending_to True\n",
      "Extending to basketball team extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 678 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   678 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.98 ms /   690 tokens\n",
      " 13%|        | 121/900 [02:09<10:35,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from movie movie on link film director\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1149 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1149 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     326.60 ms /  1165 tokens\n",
      " 14%|        | 122/900 [02:10<10:38,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 664 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   664 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     207.99 ms /   675 tokens\n",
      " 14%|        | 123/900 [02:10<09:46,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work album on link auteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1141 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1141 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    36 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     566.48 ms /  1177 tokens\n",
      " 14%|        | 124/900 [02:11<11:07,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 758 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   758 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     8 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     179.41 ms /   766 tokens\n",
      " 14%|        | 125/900 [02:12<09:57,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Organisation member extending_to True\n",
      "Extending to Organisation member extending_to False\n",
      "Downgraded from organisation company on link organisation member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1154 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1154 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     507.71 ms /  1185 tokens\n",
      " 14%|        | 126/900 [02:13<11:21,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from sports team sports team on link current member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1166 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1166 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     413.85 ms /  1189 tokens\n",
      " 14%|        | 127/900 [02:14<11:33,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work movie on link auteur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1124 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1124 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.27 ms /  1145 tokens\n",
      " 14%|        | 128/900 [02:15<11:48,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to route of transportation extending_to False\n",
      "Extending to route of transportation extending_to False\n",
      "Extending to station extending_to False\n",
      "Downgraded from route of transportation route of transportation on link route end\n",
      "Extending to station extending_to True\n",
      "Extending to route of transportation extending_to True\n",
      "Downgraded from station station on link route end\n",
      "Extending to station extending_to True\n",
      "Extending to station extending_to False\n",
      "Downgraded from route of transportation route of transportation on link route end\n",
      "Extending to station extending_to True\n",
      "Extending to station extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1741 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1741 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     387.36 ms /  1756 tokens\n",
      " 14%|        | 129/900 [02:16<11:33,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to False\n",
      "Extending to animal extending_to True\n",
      "Downgraded from place place on link birth place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1105 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     327.39 ms /  1121 tokens\n",
      " 14%|        | 130/900 [02:17<11:46,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from television show television show on link presenter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1177 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1177 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.80 ms /  1200 tokens\n",
      " 15%|        | 131/900 [02:18<11:47,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to organisation extending_to False\n",
      "Downgraded from architectural structure infrastructure on link tenant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1144 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.70 ms /  1161 tokens\n",
      " 15%|        | 132/900 [02:19<11:47,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to movie extending_to True\n",
      "Downgraded from person person on link editing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1119 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1119 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    39 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     601.22 ms /  1158 tokens\n",
      " 15%|        | 133/900 [02:20<12:58,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to False\n",
      "Downgraded from television show television show on link ending theme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1133 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.88 ms /  1154 tokens\n",
      " 15%|        | 134/900 [02:21<12:03,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to False\n",
      "Downgraded from agent sports club on link home town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1154 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1154 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     509.67 ms /  1185 tokens\n",
      " 15%|        | 135/900 [02:22<12:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to agent extending_to False\n",
      "Downgraded from musical work musical work on link performer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1103 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     407.43 ms /  1126 tokens\n",
      " 15%|        | 136/900 [02:23<11:59,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from organisation organisation on link employer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1137 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1137 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     376.16 ms /  1157 tokens\n",
      " 15%|        | 137/900 [02:24<11:56,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to mountain extending_to False\n",
      "Downgraded from river river on link mouth mountain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1156 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1156 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     363.10 ms /  1175 tokens\n",
      " 15%|        | 138/900 [02:24<11:03,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to soccer player extending_to True\n",
      "Downgraded from sports team sports team on link trainer club\n",
      "Extending to soccer player extending_to True\n",
      "Downgraded from sports team sports team on link trainer club\n",
      "Extending to soccer player extending_to True\n",
      "Downgraded from sports team hockey team on link trainer club\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1902 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1902 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     397.03 ms /  1916 tokens\n",
      " 15%|        | 139/900 [02:25<11:22,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Sports team member extending_to False\n",
      "Extending to Sports team member extending_to True\n",
      "Extending to Sports team member extending_to True\n",
      "Extending to Sports team member extending_to False\n",
      "Extending to Sports team member extending_to False\n",
      "Extending to Sports team member extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 684 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   684 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     248.70 ms /   698 tokens\n",
      " 16%|        | 140/900 [02:26<10:31,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to False\n",
      "Downgraded from sports event sports event on link champion in double female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1164 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1164 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     423.21 ms /  1188 tokens\n",
      " 16%|        | 141/900 [02:27<10:36,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to river extending_to False\n",
      "Downgraded from body of water river on link outflow\n",
      "Extending to river extending_to False\n",
      "Downgraded from place place on link river\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1443 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1443 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    48 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     743.96 ms /  1491 tokens\n",
      " 16%|        | 142/900 [02:28<13:16,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to False\n",
      "Downgraded from agent organisation on link home town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1160 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    47 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     698.68 ms /  1207 tokens\n",
      " 16%|        | 143/900 [02:29<13:50,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to True\n",
      "Downgraded from city city on link capital\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1145 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     407.97 ms /  1168 tokens\n",
      " 16%|        | 144/900 [02:30<12:56,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 671 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   671 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     375.58 ms /   696 tokens\n",
      " 16%|        | 145/900 [02:31<12:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to False\n",
      "Extending to populated place extending_to False\n",
      "Downgraded from place park on link nearest city\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1152 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1152 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     342.81 ms /  1168 tokens\n",
      " 16%|        | 146/900 [02:32<12:05,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from work book on link author\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1136 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     326.70 ms /  1152 tokens\n",
      " 16%|        | 147/900 [02:33<11:57,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to place extending_to False\n",
      "Downgraded from animal person on link death place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1093 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1093 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    43 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     645.69 ms /  1136 tokens\n",
      " 16%|        | 148/900 [02:34<12:59,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to True\n",
      "Downgraded from place village on link birth place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1135 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1135 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     362.23 ms /  1154 tokens\n",
      " 17%|        | 149/900 [02:35<12:36,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to musical artist extending_to False\n",
      "Downgraded from work work on link music composer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1135 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1135 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     338.17 ms /  1152 tokens\n",
      " 17%|        | 150/900 [02:36<11:38,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to automobile engine extending_to True\n",
      "Extending to automobile engine extending_to True\n",
      "Extending to automobile engine extending_to False\n",
      "Extending to automobile engine extending_to False\n",
      "Extending to automobile engine extending_to True\n",
      "Extending to automobile extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 694 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   694 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     270.11 ms /   710 tokens\n",
      " 17%|        | 151/900 [02:36<10:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to False\n",
      "Downgraded from television show television show on link ending theme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1287 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1287 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     318.13 ms /  1301 tokens\n",
      " 17%|        | 152/900 [02:37<09:38,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to False\n",
      "Downgraded from organisation group on link headquarter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1187 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1187 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     591.61 ms /  1225 tokens\n",
      " 17%|        | 153/900 [02:38<10:43,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team cycling team on link manager club\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1161 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     399.03 ms /  1183 tokens\n",
      " 17%|        | 154/900 [02:39<10:51,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to politician extending_to True\n",
      "Downgraded from person Organisation member on link prefect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1183 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1183 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.38 ms /  1205 tokens\n",
      " 17%|        | 155/900 [02:40<10:59,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to agent extending_to False\n",
      "Downgraded from musical work single on link performer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1102 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     346.83 ms /  1120 tokens\n",
      " 17%|        | 156/900 [02:41<10:54,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from career station career station on link career station\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1138 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1138 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     352.68 ms /  1156 tokens\n",
      " 17%|        | 157/900 [02:42<11:14,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to True\n",
      "Downgraded from career station career station on link career station\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1168 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1168 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.94 ms /  1185 tokens\n",
      " 18%|        | 158/900 [02:43<11:07,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to person extending_to False\n",
      "Downgraded from sports team sports team on link current member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1166 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1166 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     411.44 ms /  1189 tokens\n",
      " 18%|        | 159/900 [02:44<11:11,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to settlement extending_to True\n",
      "Downgraded from populated place settlement on link federal state\n",
      "Extending to settlement extending_to False\n",
      "Downgraded from legislature legislature on link meeting city\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1517 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1517 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     486.84 ms /  1543 tokens\n",
      " 18%|        | 160/900 [02:45<11:39,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to False\n",
      "Downgraded from organisation organisation on link headquarter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1159 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1159 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    40 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     615.38 ms /  1199 tokens\n",
      " 18%|        | 161/900 [02:46<12:19,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from Band Band on link former band member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1275 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1275 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     448.27 ms /  1300 tokens\n",
      " 18%|        | 162/900 [02:47<12:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Organisation member extending_to False\n",
      "Downgraded from organisation Band on link organisation member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1259 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1259 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    30 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     510.11 ms /  1289 tokens\n",
      " 18%|        | 163/900 [02:48<12:51,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team basketball team on link former team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1159 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1159 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     366.68 ms /  1178 tokens\n",
      " 18%|        | 164/900 [02:49<12:13,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from sports team sports team on link current member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1162 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1162 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    53 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     773.18 ms /  1215 tokens\n",
      " 18%|        | 165/900 [02:50<13:37,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to military unit extending_to False\n",
      "Downgraded from military person military person on link military unit\n",
      "Extending to military unit extending_to False\n",
      "Downgraded from military person military person on link military unit\n",
      "Extending to military unit extending_to True\n",
      "Downgraded from person Organisation member on link notable commander\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1911 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1911 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     578.21 ms /  1940 tokens\n",
      " 18%|        | 166/900 [02:51<14:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to musical artist extending_to True\n",
      "Downgraded from Band Band on link Music Band\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1407 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1407 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     379.44 ms /  1425 tokens\n",
      " 19%|        | 167/900 [02:52<13:23,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to agent extending_to False\n",
      "Downgraded from musical work song on link performer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1185 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1185 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     378.79 ms /  1205 tokens\n",
      " 19%|        | 168/900 [02:53<12:33,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to person extending_to False\n",
      "Downgraded from sports team sports team on link current member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1146 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    40 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     612.39 ms /  1186 tokens\n",
      " 19%|        | 169/900 [02:55<13:10,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to winter sport Player extending_to False\n",
      "Extending to winter sport Player extending_to False\n",
      "Extending to winter sport Player extending_to False\n",
      "Extending to winter sport Player extending_to True\n",
      "Extending to winter sport Player extending_to True\n",
      "Extending to winter sport Player extending_to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 678 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   678 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     317.98 ms /   698 tokens\n",
      " 19%|        | 170/900 [02:55<11:25,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to person extending_to True\n",
      "Downgraded from country country on link state of origin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1146 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    28 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     470.33 ms /  1174 tokens\n",
      " 19%|        | 171/900 [02:56<11:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to company extending_to True\n",
      "Extending to song extending_to True\n",
      "Extending to company extending_to False\n",
      "Downgraded from work work on link production company\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1106 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1106 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     481.12 ms /  1135 tokens\n",
      " 19%|        | 172/900 [02:57<11:38,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to person extending_to False\n",
      "Downgraded from movie movie on link film director\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1149 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1149 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     434.71 ms /  1174 tokens\n",
      " 19%|        | 173/900 [02:58<11:35,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 664 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   664 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.90 ms /   686 tokens\n",
      " 19%|        | 174/900 [02:59<10:40,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to song extending_to False\n",
      "Extending to song extending_to False\n",
      "Extending to song extending_to True\n",
      "Extending to song extending_to False\n",
      "Extending to song extending_to True\n",
      "Extending to song extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 670 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   670 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    36 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     505.29 ms /   706 tokens\n",
      " 19%|        | 175/900 [03:00<10:17,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to work extending_to False\n",
      "Downgraded from television show television show on link opening theme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1139 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1139 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     433.51 ms /  1164 tokens\n",
      " 20%|        | 176/900 [03:01<10:40,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to True\n",
      "Downgraded from ethnic group ethnic group on link ethnic group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1140 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    28 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     468.66 ms /  1168 tokens\n",
      " 20%|        | 177/900 [03:02<11:24,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to athlete extending_to False\n",
      "Downgraded from sports event tournament on link champion in single male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1140 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     413.68 ms /  1163 tokens\n",
      " 20%|        | 178/900 [03:03<11:25,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to musical artist extending_to True\n",
      "Downgraded from Band Band on link Music Band\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1313 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1313 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    50 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     761.90 ms /  1363 tokens\n",
      " 20%|        | 179/900 [03:04<12:34,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to village extending_to False\n",
      "Extending to ethnic group extending_to False\n",
      "Downgraded from populated place settlement on link ethnic group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1146 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     483.62 ms /  1175 tokens\n",
      " 20%|        | 180/900 [03:05<11:58,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to animal extending_to False\n",
      "Extending to settlement extending_to False\n",
      "Downgraded from agent agent on link home town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1115 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    53 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     765.95 ms /  1168 tokens\n",
      " 20%|        | 181/900 [03:06<13:30,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to Organisation member extending_to True\n",
      "Extending to sports team extending_to False\n",
      "Downgraded from athlete athlete on link former team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1155 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     460.82 ms /  1181 tokens\n",
      " 20%|        | 182/900 [03:07<12:55,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to politician extending_to True\n",
      "Downgraded from person athlete on link prefect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1148 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1148 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     353.91 ms /  1165 tokens\n",
      " 20%|        | 183/900 [03:08<12:33,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to military person extending_to False\n",
      "Extending to military person extending_to True\n",
      "Downgraded from military unit military unit on link military unit\n",
      "Extending to military person extending_to False\n",
      "Extending to military person extending_to False\n",
      "Extending to military person extending_to False\n",
      "Extending to military unit extending_to True\n",
      "Downgraded from mean of transportation mean of transportation on link aircraft bomber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1518 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1518 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     471.98 ms /  1541 tokens\n",
      " 20%|        | 184/900 [03:09<12:39,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to athlete extending_to True\n",
      "Downgraded from sports team cycling team on link former team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1161 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1161 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    28 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     514.68 ms /  1189 tokens\n",
      " 21%|        | 185/900 [03:10<13:08,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to True\n",
      "Extending to career station extending_to False\n",
      "Extending to career station extending_to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 198 prefix-match hit, remaining 598 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   598 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     209.76 ms /   608 tokens\n",
      " 21%|        | 186/900 [03:11<11:39,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to populated place extending_to False\n",
      "Downgraded from organisation company on link headquarter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1153 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     426.73 ms /  1174 tokens\n",
      " 21%|        | 187/900 [03:13<13:35,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to musical work extending_to False\n",
      "Downgraded from military unit military unit on link march\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1154 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1154 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     387.56 ms /  1170 tokens\n",
      " 21%|        | 188/900 [03:14<14:11,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extending to office holder extending_to True\n",
      "Downgraded from political party political party on link other party\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 139 prefix-match hit, remaining 1164 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1043.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /  1164 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     510.72 ms /  1189 tokens\n",
      " 21%|        | 189/900 [03:15<14:51,  1.25s/it]"
     ]
    }
   ],
   "source": [
    "n_examples = 300\n",
    "n_nodes = [3, 5, 10]\n",
    "resulting_examples = []\n",
    "progress = tqdm(total=n_examples * len(n_nodes))\n",
    "for n_node in n_nodes:\n",
    "    for i in range(n_examples):\n",
    "        \n",
    "        erl = choose_graph(seed=i, max_nodes=n_node)\n",
    "        response = llama_model.create_chat_completion(\n",
    "            # grammar=self.grammar_erl,\n",
    "            messages=messages\n",
    "            + [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": erl.model_dump_json(),\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=-1,\n",
    "            temperature=0.7,  # get wild :)\n",
    "        )\n",
    "        progress.update(1)\n",
    "        resulting_examples.append(\n",
    "            {\n",
    "                \"erl\": erl.model_dump_json(),\n",
    "                \"response\": response[\"choices\"][0][\"message\"][\"content\"],\n",
    "                \"n_nodes\": n_node,\n",
    "                \"seed\": i,\n",
    "            }\n",
    "        )\n",
    "        topic_man.engine.dispose()\n",
    "        \n",
    "resulting_examples_df = pd.DataFrame(resulting_examples)\n",
    "resulting_examples_df.to_csv(\"llama_examples.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
